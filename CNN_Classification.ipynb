{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, train accuracy 0.56\n",
      "step 100, train accuracy 0.52\n",
      "step 200, train accuracy 0.67\n",
      "step 300, train accuracy 0.6\n",
      "step 400, train accuracy 0.68\n",
      "step 500, train accuracy 0.65\n",
      "step 600, train accuracy 0.65\n",
      "step 700, train accuracy 0.66\n",
      "step 800, train accuracy 0.66\n",
      "step 900, train accuracy 0.6\n",
      "step 1000, train accuracy 0.6\n",
      "step 1100, train accuracy 0.61\n",
      "step 1200, train accuracy 0.65\n",
      "step 1300, train accuracy 0.65\n",
      "step 1400, train accuracy 0.61\n",
      "step 1500, train accuracy 0.73\n",
      "step 1600, train accuracy 0.73\n",
      "step 1700, train accuracy 0.57\n",
      "step 1800, train accuracy 0.68\n",
      "step 1900, train accuracy 0.71\n",
      "step 2000, train accuracy 0.63\n",
      "step 2100, train accuracy 0.62\n",
      "step 2200, train accuracy 0.62\n",
      "step 2300, train accuracy 0.72\n",
      "step 2400, train accuracy 0.57\n",
      "step 2500, train accuracy 0.63\n",
      "step 2600, train accuracy 0.63\n",
      "step 2700, train accuracy 0.66\n",
      "step 2800, train accuracy 0.63\n",
      "step 2900, train accuracy 0.7\n",
      "step 3000, train accuracy 0.68\n",
      "step 3100, train accuracy 0.57\n",
      "step 3200, train accuracy 0.74\n",
      "step 3300, train accuracy 0.74\n",
      "step 3400, train accuracy 0.73\n",
      "step 3500, train accuracy 0.68\n",
      "step 3600, train accuracy 0.63\n",
      "step 3700, train accuracy 0.66\n",
      "step 3800, train accuracy 0.72\n",
      "step 3900, train accuracy 0.66\n",
      "step 4000, train accuracy 0.69\n",
      "step 4100, train accuracy 0.62\n",
      "step 4200, train accuracy 0.59\n",
      "step 4300, train accuracy 0.67\n",
      "step 4400, train accuracy 0.71\n",
      "step 4500, train accuracy 0.7\n",
      "step 4600, train accuracy 0.73\n",
      "step 4700, train accuracy 0.65\n",
      "step 4800, train accuracy 0.68\n",
      "step 4900, train accuracy 0.65\n",
      "step 5000, train accuracy 0.69\n",
      "step 5100, train accuracy 0.71\n",
      "step 5200, train accuracy 0.63\n",
      "step 5300, train accuracy 0.66\n",
      "step 5400, train accuracy 0.65\n",
      "step 5500, train accuracy 0.71\n",
      "step 5600, train accuracy 0.73\n",
      "step 5700, train accuracy 0.64\n",
      "step 5800, train accuracy 0.71\n",
      "step 5900, train accuracy 0.68\n",
      "step 6000, train accuracy 0.69\n",
      "step 6100, train accuracy 0.73\n",
      "step 6200, train accuracy 0.65\n",
      "step 6300, train accuracy 0.68\n",
      "step 6400, train accuracy 0.76\n",
      "step 6500, train accuracy 0.73\n",
      "step 6600, train accuracy 0.63\n",
      "step 6700, train accuracy 0.67\n",
      "step 6800, train accuracy 0.71\n",
      "step 6900, train accuracy 0.72\n",
      "step 7000, train accuracy 0.63\n",
      "step 7100, train accuracy 0.66\n",
      "step 7200, train accuracy 0.68\n",
      "step 7300, train accuracy 0.73\n",
      "step 7400, train accuracy 0.67\n",
      "step 7500, train accuracy 0.67\n",
      "step 7600, train accuracy 0.65\n",
      "step 7700, train accuracy 0.71\n",
      "step 7800, train accuracy 0.65\n",
      "step 7900, train accuracy 0.65\n",
      "step 8000, train accuracy 0.66\n",
      "step 8100, train accuracy 0.71\n",
      "step 8200, train accuracy 0.67\n",
      "step 8300, train accuracy 0.76\n",
      "step 8400, train accuracy 0.66\n",
      "step 8500, train accuracy 0.73\n",
      "step 8600, train accuracy 0.72\n",
      "step 8700, train accuracy 0.62\n",
      "step 8800, train accuracy 0.7\n",
      "step 8900, train accuracy 0.72\n",
      "step 9000, train accuracy 0.77\n",
      "step 9100, train accuracy 0.7\n",
      "step 9200, train accuracy 0.61\n",
      "step 9300, train accuracy 0.68\n",
      "step 9400, train accuracy 0.67\n",
      "step 9500, train accuracy 0.68\n",
      "step 9600, train accuracy 0.78\n",
      "step 9700, train accuracy 0.66\n",
      "step 9800, train accuracy 0.65\n",
      "step 9900, train accuracy 0.77\n",
      "step 10000, train accuracy 0.77\n",
      "step 10100, train accuracy 0.68\n",
      "step 10200, train accuracy 0.69\n",
      "step 10300, train accuracy 0.64\n",
      "step 10400, train accuracy 0.76\n",
      "step 10500, train accuracy 0.71\n",
      "step 10600, train accuracy 0.65\n",
      "step 10700, train accuracy 0.73\n",
      "step 10800, train accuracy 0.74\n",
      "step 10900, train accuracy 0.69\n",
      "step 11000, train accuracy 0.73\n",
      "step 11100, train accuracy 0.72\n",
      "step 11200, train accuracy 0.72\n",
      "step 11300, train accuracy 0.8\n",
      "step 11400, train accuracy 0.69\n",
      "step 11500, train accuracy 0.73\n",
      "step 11600, train accuracy 0.76\n",
      "step 11700, train accuracy 0.77\n",
      "step 11800, train accuracy 0.8\n",
      "step 11900, train accuracy 0.67\n",
      "step 12000, train accuracy 0.78\n",
      "step 12100, train accuracy 0.68\n",
      "step 12200, train accuracy 0.72\n",
      "step 12300, train accuracy 0.72\n",
      "step 12400, train accuracy 0.69\n",
      "step 12500, train accuracy 0.74\n",
      "step 12600, train accuracy 0.77\n",
      "step 12700, train accuracy 0.71\n",
      "step 12800, train accuracy 0.67\n",
      "step 12900, train accuracy 0.72\n",
      "step 13000, train accuracy 0.67\n",
      "step 13100, train accuracy 0.74\n",
      "step 13200, train accuracy 0.78\n",
      "step 13300, train accuracy 0.67\n",
      "step 13400, train accuracy 0.71\n",
      "step 13500, train accuracy 0.73\n",
      "step 13600, train accuracy 0.75\n",
      "step 13700, train accuracy 0.67\n",
      "step 13800, train accuracy 0.69\n",
      "step 13900, train accuracy 0.72\n",
      "step 14000, train accuracy 0.69\n",
      "step 14100, train accuracy 0.83\n",
      "step 14200, train accuracy 0.7\n",
      "step 14300, train accuracy 0.75\n",
      "step 14400, train accuracy 0.73\n",
      "step 14500, train accuracy 0.78\n",
      "step 14600, train accuracy 0.7\n",
      "step 14700, train accuracy 0.71\n",
      "step 14800, train accuracy 0.74\n",
      "step 14900, train accuracy 0.76\n",
      "step 15000, train accuracy 0.76\n",
      "step 15100, train accuracy 0.71\n",
      "step 15200, train accuracy 0.77\n",
      "step 15300, train accuracy 0.69\n",
      "step 15400, train accuracy 0.71\n",
      "step 15500, train accuracy 0.75\n",
      "step 15600, train accuracy 0.75\n",
      "step 15700, train accuracy 0.77\n",
      "step 15800, train accuracy 0.74\n",
      "step 15900, train accuracy 0.67\n",
      "step 16000, train accuracy 0.7\n",
      "step 16100, train accuracy 0.71\n",
      "step 16200, train accuracy 0.73\n",
      "step 16300, train accuracy 0.79\n",
      "step 16400, train accuracy 0.72\n",
      "step 16500, train accuracy 0.73\n",
      "step 16600, train accuracy 0.74\n",
      "step 16700, train accuracy 0.74\n",
      "step 16800, train accuracy 0.73\n",
      "step 16900, train accuracy 0.66\n",
      "step 17000, train accuracy 0.73\n",
      "step 17100, train accuracy 0.77\n",
      "step 17200, train accuracy 0.74\n",
      "step 17300, train accuracy 0.65\n",
      "step 17400, train accuracy 0.75\n",
      "step 17500, train accuracy 0.78\n",
      "step 17600, train accuracy 0.74\n",
      "step 17700, train accuracy 0.69\n",
      "step 17800, train accuracy 0.8\n",
      "step 17900, train accuracy 0.74\n",
      "step 18000, train accuracy 0.76\n",
      "step 18100, train accuracy 0.76\n",
      "step 18200, train accuracy 0.74\n",
      "step 18300, train accuracy 0.82\n",
      "step 18400, train accuracy 0.76\n",
      "step 18500, train accuracy 0.81\n",
      "step 18600, train accuracy 0.79\n",
      "step 18700, train accuracy 0.79\n",
      "step 18800, train accuracy 0.73\n",
      "step 18900, train accuracy 0.78\n",
      "step 19000, train accuracy 0.75\n",
      "step 19100, train accuracy 0.81\n",
      "step 19200, train accuracy 0.66\n",
      "step 19300, train accuracy 0.77\n",
      "step 19400, train accuracy 0.73\n",
      "step 19500, train accuracy 0.8\n",
      "step 19600, train accuracy 0.8\n",
      "step 19700, train accuracy 0.77\n",
      "step 19800, train accuracy 0.78\n",
      "step 19900, train accuracy 0.78\n",
      "step 20000, train accuracy 0.7\n",
      "step 20100, train accuracy 0.77\n",
      "step 20200, train accuracy 0.7\n",
      "step 20300, train accuracy 0.73\n",
      "step 20400, train accuracy 0.75\n",
      "step 20500, train accuracy 0.75\n",
      "step 20600, train accuracy 0.75\n",
      "step 20700, train accuracy 0.74\n",
      "step 20800, train accuracy 0.76\n",
      "step 20900, train accuracy 0.71\n",
      "step 21000, train accuracy 0.81\n",
      "step 21100, train accuracy 0.73\n",
      "step 21200, train accuracy 0.71\n",
      "step 21300, train accuracy 0.8\n",
      "step 21400, train accuracy 0.8\n",
      "step 21500, train accuracy 0.7\n",
      "step 21600, train accuracy 0.88\n",
      "step 21700, train accuracy 0.77\n",
      "step 21800, train accuracy 0.73\n",
      "step 21900, train accuracy 0.83\n",
      "step 22000, train accuracy 0.7\n",
      "step 22100, train accuracy 0.76\n",
      "step 22200, train accuracy 0.77\n",
      "step 22300, train accuracy 0.84\n",
      "step 22400, train accuracy 0.72\n",
      "step 22500, train accuracy 0.81\n",
      "step 22600, train accuracy 0.76\n",
      "step 22700, train accuracy 0.79\n",
      "step 22800, train accuracy 0.77\n",
      "step 22900, train accuracy 0.81\n",
      "step 23000, train accuracy 0.88\n",
      "step 23100, train accuracy 0.7\n",
      "step 23200, train accuracy 0.77\n",
      "step 23300, train accuracy 0.76\n",
      "step 23400, train accuracy 0.8\n",
      "step 23500, train accuracy 0.77\n",
      "step 23600, train accuracy 0.75\n",
      "step 23700, train accuracy 0.76\n",
      "step 23800, train accuracy 0.8\n",
      "step 23900, train accuracy 0.7\n",
      "step 24000, train accuracy 0.73\n",
      "step 24100, train accuracy 0.78\n",
      "step 24200, train accuracy 0.81\n",
      "step 24300, train accuracy 0.69\n",
      "step 24400, train accuracy 0.75\n",
      "step 24500, train accuracy 0.7\n",
      "step 24600, train accuracy 0.82\n",
      "step 24700, train accuracy 0.77\n",
      "step 24800, train accuracy 0.81\n",
      "step 24900, train accuracy 0.84\n",
      "step 25000, train accuracy 0.81\n",
      "step 25100, train accuracy 0.79\n",
      "step 25200, train accuracy 0.74\n",
      "step 25300, train accuracy 0.82\n",
      "step 25400, train accuracy 0.78\n",
      "step 25500, train accuracy 0.8\n",
      "step 25600, train accuracy 0.75\n",
      "step 25700, train accuracy 0.79\n",
      "step 25800, train accuracy 0.8\n",
      "step 25900, train accuracy 0.85\n",
      "step 26000, train accuracy 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26100, train accuracy 0.84\n",
      "step 26200, train accuracy 0.85\n",
      "step 26300, train accuracy 0.82\n",
      "step 26400, train accuracy 0.76\n",
      "step 26500, train accuracy 0.81\n",
      "step 26600, train accuracy 0.79\n",
      "step 26700, train accuracy 0.87\n",
      "step 26800, train accuracy 0.84\n",
      "step 26900, train accuracy 0.84\n",
      "step 27000, train accuracy 0.81\n",
      "step 27100, train accuracy 0.8\n",
      "step 27200, train accuracy 0.84\n",
      "step 27300, train accuracy 0.76\n",
      "step 27400, train accuracy 0.78\n",
      "step 27500, train accuracy 0.73\n",
      "step 27600, train accuracy 0.79\n",
      "step 27700, train accuracy 0.79\n",
      "step 27800, train accuracy 0.78\n",
      "step 27900, train accuracy 0.83\n",
      "step 28000, train accuracy 0.77\n",
      "step 28100, train accuracy 0.76\n",
      "step 28200, train accuracy 0.85\n",
      "step 28300, train accuracy 0.79\n",
      "step 28400, train accuracy 0.82\n",
      "step 28500, train accuracy 0.83\n",
      "step 28600, train accuracy 0.72\n",
      "step 28700, train accuracy 0.76\n",
      "step 28800, train accuracy 0.81\n",
      "step 28900, train accuracy 0.81\n",
      "step 29000, train accuracy 0.78\n",
      "step 29100, train accuracy 0.8\n",
      "step 29200, train accuracy 0.83\n",
      "step 29300, train accuracy 0.8\n",
      "step 29400, train accuracy 0.84\n",
      "step 29500, train accuracy 0.79\n",
      "step 29600, train accuracy 0.78\n",
      "step 29700, train accuracy 0.77\n",
      "step 29800, train accuracy 0.83\n",
      "step 29900, train accuracy 0.73\n",
      "step 30000, train accuracy 0.8\n",
      "step 30100, train accuracy 0.77\n",
      "step 30200, train accuracy 0.74\n",
      "step 30300, train accuracy 0.82\n",
      "step 30400, train accuracy 0.77\n",
      "step 30500, train accuracy 0.85\n",
      "step 30600, train accuracy 0.8\n",
      "step 30700, train accuracy 0.8\n",
      "step 30800, train accuracy 0.8\n",
      "step 30900, train accuracy 0.78\n",
      "step 31000, train accuracy 0.8\n",
      "step 31100, train accuracy 0.81\n",
      "step 31200, train accuracy 0.77\n",
      "step 31300, train accuracy 0.84\n",
      "step 31400, train accuracy 0.85\n",
      "step 31500, train accuracy 0.87\n",
      "step 31600, train accuracy 0.85\n",
      "step 31700, train accuracy 0.85\n",
      "step 31800, train accuracy 0.85\n",
      "step 31900, train accuracy 0.89\n",
      "step 32000, train accuracy 0.83\n",
      "step 32100, train accuracy 0.78\n",
      "step 32200, train accuracy 0.85\n",
      "step 32300, train accuracy 0.8\n",
      "step 32400, train accuracy 0.8\n",
      "step 32500, train accuracy 0.85\n",
      "step 32600, train accuracy 0.84\n",
      "step 32700, train accuracy 0.81\n",
      "step 32800, train accuracy 0.79\n",
      "step 32900, train accuracy 0.79\n",
      "step 33000, train accuracy 0.84\n",
      "step 33100, train accuracy 0.74\n",
      "step 33200, train accuracy 0.77\n",
      "step 33300, train accuracy 0.78\n",
      "step 33400, train accuracy 0.81\n",
      "step 33500, train accuracy 0.81\n",
      "step 33600, train accuracy 0.88\n",
      "step 33700, train accuracy 0.84\n",
      "step 33800, train accuracy 0.87\n",
      "step 33900, train accuracy 0.83\n",
      "step 34000, train accuracy 0.78\n",
      "step 34100, train accuracy 0.82\n",
      "step 34200, train accuracy 0.8\n",
      "step 34300, train accuracy 0.85\n",
      "step 34400, train accuracy 0.84\n",
      "step 34500, train accuracy 0.86\n",
      "step 34600, train accuracy 0.8\n",
      "step 34700, train accuracy 0.82\n",
      "step 34800, train accuracy 0.85\n",
      "step 34900, train accuracy 0.8\n",
      "step 35000, train accuracy 0.8\n",
      "step 35100, train accuracy 0.9\n",
      "step 35200, train accuracy 0.83\n",
      "step 35300, train accuracy 0.87\n",
      "step 35400, train accuracy 0.9\n",
      "step 35500, train accuracy 0.88\n",
      "step 35600, train accuracy 0.87\n",
      "step 35700, train accuracy 0.82\n",
      "step 35800, train accuracy 0.84\n",
      "step 35900, train accuracy 0.83\n",
      "step 36000, train accuracy 0.85\n",
      "step 36100, train accuracy 0.74\n",
      "step 36200, train accuracy 0.79\n",
      "step 36300, train accuracy 0.84\n",
      "step 36400, train accuracy 0.87\n",
      "step 36500, train accuracy 0.91\n",
      "step 36600, train accuracy 0.86\n",
      "step 36700, train accuracy 0.86\n",
      "step 36800, train accuracy 0.86\n",
      "step 36900, train accuracy 0.86\n",
      "step 37000, train accuracy 0.89\n",
      "step 37100, train accuracy 0.9\n",
      "step 37200, train accuracy 0.84\n",
      "step 37300, train accuracy 0.88\n",
      "step 37400, train accuracy 0.89\n",
      "step 37500, train accuracy 0.87\n",
      "step 37600, train accuracy 0.83\n",
      "step 37700, train accuracy 0.84\n",
      "step 37800, train accuracy 0.84\n",
      "step 37900, train accuracy 0.92\n",
      "step 38000, train accuracy 0.83\n",
      "step 38100, train accuracy 0.87\n",
      "step 38200, train accuracy 0.88\n",
      "step 38300, train accuracy 0.88\n",
      "step 38400, train accuracy 0.84\n",
      "step 38500, train accuracy 0.88\n",
      "step 38600, train accuracy 0.95\n",
      "step 38700, train accuracy 0.83\n",
      "step 38800, train accuracy 0.86\n",
      "step 38900, train accuracy 0.89\n",
      "step 39000, train accuracy 0.89\n",
      "step 39100, train accuracy 0.85\n",
      "step 39200, train accuracy 0.86\n",
      "step 39300, train accuracy 0.92\n",
      "step 39400, train accuracy 0.8\n",
      "step 39500, train accuracy 0.82\n",
      "step 39600, train accuracy 0.85\n",
      "step 39700, train accuracy 0.86\n",
      "step 39800, train accuracy 0.86\n",
      "step 39900, train accuracy 0.83\n",
      "step 40000, train accuracy 0.9\n",
      "step 40100, train accuracy 0.91\n",
      "step 40200, train accuracy 0.85\n",
      "step 40300, train accuracy 0.91\n",
      "step 40400, train accuracy 0.88\n",
      "step 40500, train accuracy 0.88\n",
      "step 40600, train accuracy 0.87\n",
      "step 40700, train accuracy 0.85\n",
      "step 40800, train accuracy 0.92\n",
      "step 40900, train accuracy 0.92\n",
      "step 41000, train accuracy 0.81\n",
      "step 41100, train accuracy 0.88\n",
      "step 41200, train accuracy 0.85\n",
      "step 41300, train accuracy 0.84\n",
      "step 41400, train accuracy 0.85\n",
      "step 41500, train accuracy 0.91\n",
      "step 41600, train accuracy 0.93\n",
      "step 41700, train accuracy 0.93\n",
      "step 41800, train accuracy 0.88\n",
      "step 41900, train accuracy 0.91\n",
      "step 42000, train accuracy 0.9\n",
      "step 42100, train accuracy 0.83\n",
      "step 42200, train accuracy 0.88\n",
      "step 42300, train accuracy 0.87\n",
      "step 42400, train accuracy 0.87\n",
      "step 42500, train accuracy 0.88\n",
      "step 42600, train accuracy 0.89\n",
      "step 42700, train accuracy 0.88\n",
      "step 42800, train accuracy 0.89\n",
      "step 42900, train accuracy 0.91\n",
      "step 43000, train accuracy 0.87\n",
      "step 43100, train accuracy 0.89\n",
      "step 43200, train accuracy 0.88\n",
      "step 43300, train accuracy 0.88\n",
      "step 43400, train accuracy 0.92\n",
      "step 43500, train accuracy 0.84\n",
      "step 43600, train accuracy 0.88\n",
      "step 43700, train accuracy 0.86\n",
      "step 43800, train accuracy 0.83\n",
      "step 43900, train accuracy 0.95\n",
      "step 44000, train accuracy 0.83\n",
      "step 44100, train accuracy 0.83\n",
      "step 44200, train accuracy 0.96\n",
      "step 44300, train accuracy 0.82\n",
      "step 44400, train accuracy 0.88\n",
      "step 44500, train accuracy 0.87\n",
      "step 44600, train accuracy 0.93\n",
      "step 44700, train accuracy 0.92\n",
      "step 44800, train accuracy 0.94\n",
      "step 44900, train accuracy 0.88\n",
      "step 45000, train accuracy 0.86\n",
      "step 45100, train accuracy 0.83\n",
      "step 45200, train accuracy 0.81\n",
      "step 45300, train accuracy 0.91\n",
      "step 45400, train accuracy 0.91\n",
      "step 45500, train accuracy 0.85\n",
      "step 45600, train accuracy 0.86\n",
      "step 45700, train accuracy 0.9\n",
      "step 45800, train accuracy 0.86\n",
      "step 45900, train accuracy 0.89\n",
      "step 46000, train accuracy 0.92\n",
      "step 46100, train accuracy 0.92\n",
      "step 46200, train accuracy 0.91\n",
      "step 46300, train accuracy 0.91\n",
      "step 46400, train accuracy 0.87\n",
      "step 46500, train accuracy 0.86\n",
      "step 46600, train accuracy 0.92\n",
      "step 46700, train accuracy 0.91\n",
      "step 46800, train accuracy 0.92\n",
      "step 46900, train accuracy 0.9\n",
      "step 47000, train accuracy 0.86\n",
      "step 47100, train accuracy 0.92\n",
      "step 47200, train accuracy 0.91\n",
      "step 47300, train accuracy 0.88\n",
      "step 47400, train accuracy 0.93\n",
      "step 47500, train accuracy 0.86\n",
      "step 47600, train accuracy 0.87\n",
      "step 47700, train accuracy 0.91\n",
      "step 47800, train accuracy 0.95\n",
      "step 47900, train accuracy 0.9\n",
      "step 48000, train accuracy 0.91\n",
      "step 48100, train accuracy 0.9\n",
      "step 48200, train accuracy 0.93\n",
      "step 48300, train accuracy 0.94\n",
      "step 48400, train accuracy 0.9\n",
      "step 48500, train accuracy 0.94\n",
      "step 48600, train accuracy 0.83\n",
      "step 48700, train accuracy 0.91\n",
      "step 48800, train accuracy 0.98\n",
      "step 48900, train accuracy 0.88\n",
      "step 49000, train accuracy 0.92\n",
      "step 49100, train accuracy 0.9\n",
      "step 49200, train accuracy 0.89\n",
      "step 49300, train accuracy 0.96\n",
      "step 49400, train accuracy 0.9\n",
      "step 49500, train accuracy 0.93\n",
      "step 49600, train accuracy 0.88\n",
      "step 49700, train accuracy 0.94\n",
      "step 49800, train accuracy 0.92\n",
      "step 49900, train accuracy 0.95\n"
     ]
    }
   ],
   "source": [
    "# start tensorflow interactiveSession                baseline           F1 = 0.7377938517\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#####################################################     Net Define     ##################################################### \n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# pooling\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Create the model\n",
    "# placeholder\n",
    "x = tf.placeholder(\"float\", [None, 2500])\n",
    "y_ = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "\n",
    "# first convolutinal layer\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 50, 50, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second convolutional layer\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# densely connected layer\n",
    "w_fc1 = weight_variable([13*13*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 13*13*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# readout layer\n",
    "w_fc2 = weight_variable([1024, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)\n",
    "\n",
    "# train and evaluate the model\n",
    "#交叉熵作为损失函数\n",
    "delta = 1e-7\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv+delta))\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "#####################################################       Train     ##################################################### \n",
    "\n",
    "image_path = 'E:/Age Detection of Indian Actors/train_DETg9GD/Train_Gray/'\n",
    "data_path = 'E:/Age Detection of Indian Actors/train_DETg9GD/Train.csv'\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data = pd.get_dummies(data,columns = ['Class'])\n",
    "\n",
    "\n",
    "def get_batch(data,batch_rate,seed):\n",
    "    \"\"\"\n",
    "    本函数实现从训练集中随机抽取部分图像，格式适合输入tensorflow，同时得到样本label的独热编码\n",
    "    input:\n",
    "        batch_rate:    batch占训练集数据的比例\n",
    "        data:          DataFrame       train.csv\n",
    "        seed:          随机种子\n",
    "    output:\n",
    "        train_x:        训练图像tensor\n",
    "        train_y:        训练图像one_hot编码的label\n",
    "    \"\"\"\n",
    "    sample = data.sample(frac = batch_rate, random_state = seed)\n",
    "    sample.index = list(range(0,sample.shape[0]))\n",
    "    one_hot_sample = sample.drop(['ID'], axis = 1)\n",
    "    train_y = one_hot_sample.values\n",
    "    train_x = []\n",
    "    for i in range(0,sample.shape[0]):\n",
    "        image = image_path + sample.ID[i]\n",
    "        im = np.array(Image.open(image))/255.0\n",
    "        im = im.flatten()\n",
    "        train_x.append(im)\n",
    "    train_x = np.array(train_x)\n",
    "    \n",
    "    return train_x,train_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "batch_rate = 0.005\n",
    "for i in range(50000):\n",
    "    batch_x,batch_y = get_batch(data,batch_rate,i)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_x, y_:batch_y, keep_prob:1.0})\n",
    "        print (\"step %d, train accuracy %g\" %(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch_x, y_:batch_y, keep_prob:0.5})\n",
    "\n",
    "#print (\"test accuracy %g\" % accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 0, 2, 2,\n",
       "       0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 1, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2,\n",
       "       2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 2, 0,\n",
       "       2, 0, 2, 0, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 1, 0, 2, 2, 0, 1, 0, 2,\n",
       "       2, 2, 0, 0, 2, 0, 2, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tf.argmax(y_conv, 1)\n",
    "P = pred.eval(feed_dict={x:batch_x, y_:batch_y, keep_prob:1.0})\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-824ff3464036>\", line 39, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n  File \"<ipython-input-4-824ff3464036>\", line 22, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e96c8f690c17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mtest_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \"\"\"\n\u001b[1;32m--> 707\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5211\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5212\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5213\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-824ff3464036>\", line 39, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n  File \"<ipython-input-4-824ff3464036>\", line 22, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "image_path = 'E:/Age Detection of Indian Actors/test_Bh8pGW3/Test_Gray/'\n",
    "\n",
    "test = pd.read_csv('E:/Age Detection of Indian Actors/test_Bh8pGW3/test.csv')\n",
    "\n",
    "test_x = []\n",
    "for i in range(0,test.shape[0]):\n",
    "    image = image_path + test.ID[i]\n",
    "    im = np.array(Image.open(image))/255.0\n",
    "    im = im.flatten()\n",
    "    test_x.append(im)\n",
    "test_x = np.array(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-824ff3464036>\", line 39, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n  File \"<ipython-input-4-824ff3464036>\", line 22, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f03aaa7be84d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \"\"\"\n\u001b[1;32m--> 707\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5211\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5212\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5213\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'Conv2D_6', defined at:\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-824ff3464036>\", line 39, in <module>\n    h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n  File \"<ipython-input-4-824ff3464036>\", line 22, in conv2d\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3414, in create_op\n    op_def=op_def)\n  File \"E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1740, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[6636,32,50,50] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: Conv2D_6 = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](Reshape_6, Variable_24/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: ArgMax_9/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_70_ArgMax_9\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "test_y = np.zeros((test.shape[0],3))\n",
    "P = pred.eval(feed_dict={x:test_x, y_:test_y, keep_prob:1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_0 = test_x[0:1500]\n",
    "test_y_0 = test_y[0:1500]\n",
    "P_0 = pred.eval(feed_dict={x:test_x_0, y_:test_y_0, keep_prob:1.0})\n",
    "\n",
    "test_x_1 = test_x[1500:3000]\n",
    "test_y_1 = test_y[1500:3000]\n",
    "P_1 = pred.eval(feed_dict={x:test_x_1, y_:test_y_1, keep_prob:1.0})\n",
    "\n",
    "test_x_2 = test_x[3000:4500]\n",
    "test_y_2 = test_y[3000:4500]\n",
    "P_2 = pred.eval(feed_dict={x:test_x_2, y_:test_y_2, keep_prob:1.0})\n",
    "\n",
    "test_x_3 = test_x[4500:]\n",
    "test_y_3 = test_y[4500:]\n",
    "P_3 = pred.eval(feed_dict={x:test_x_3, y_:test_y_3, keep_prob:3.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6636,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = np.hstack([P_0,P_1,P_2,P_3])\n",
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['pred'] = P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25321.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>989.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19277.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13093.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5367.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  pred\n",
       "0  25321.jpg     0\n",
       "1    989.jpg     2\n",
       "2  19277.jpg     0\n",
       "3  13093.jpg     0\n",
       "4   5367.jpg     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>25321.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOUNG</td>\n",
       "      <td>989.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>19277.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MIDDLE</td>\n",
       "      <td>13093.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OLD</td>\n",
       "      <td>5367.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class         ID\n",
       "0  MIDDLE  25321.jpg\n",
       "1   YOUNG    989.jpg\n",
       "2  MIDDLE  19277.jpg\n",
       "3  MIDDLE  13093.jpg\n",
       "4     OLD   5367.jpg"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict = {0:'MIDDLE',1:'OLD', 2:'YOUNG'}\n",
    "Class = []\n",
    "for i in range(0,test.shape[0]):\n",
    "    Class.append(Dict.get(test['pred'][i]))\n",
    "    \n",
    "pred = pd.DataFrame({'Class':Class,'ID':test.ID})\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('50_gray_pix_pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:118: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step 0, train accuracy 0.34\n",
      "step 200, train accuracy 0.67\n",
      "step 400, train accuracy 0.67\n",
      "step 600, train accuracy 0.71\n",
      "step 800, train accuracy 0.68\n",
      "step 1000, train accuracy 0.61\n",
      "step 1200, train accuracy 0.66\n",
      "step 1400, train accuracy 0.58\n",
      "step 1600, train accuracy 0.73\n",
      "step 1800, train accuracy 0.66\n",
      "step 2000, train accuracy 0.59\n",
      "step 2200, train accuracy 0.65\n",
      "step 2400, train accuracy 0.6\n",
      "step 2600, train accuracy 0.7\n",
      "step 2800, train accuracy 0.64\n",
      "step 3000, train accuracy 0.68\n",
      "step 3200, train accuracy 0.68\n",
      "step 3400, train accuracy 0.73\n",
      "step 3600, train accuracy 0.62\n",
      "step 3800, train accuracy 0.73\n",
      "step 4000, train accuracy 0.71\n",
      "step 4200, train accuracy 0.57\n",
      "step 4400, train accuracy 0.71\n",
      "step 4600, train accuracy 0.73\n",
      "step 4800, train accuracy 0.72\n",
      "step 5000, train accuracy 0.72\n",
      "step 5200, train accuracy 0.65\n",
      "step 5400, train accuracy 0.66\n",
      "step 5600, train accuracy 0.73\n",
      "step 5800, train accuracy 0.66\n",
      "step 6000, train accuracy 0.7\n",
      "step 6200, train accuracy 0.69\n",
      "step 6400, train accuracy 0.74\n",
      "step 6600, train accuracy 0.68\n",
      "step 6800, train accuracy 0.69\n",
      "step 7000, train accuracy 0.71\n",
      "step 7200, train accuracy 0.71\n",
      "step 7400, train accuracy 0.69\n",
      "step 7600, train accuracy 0.69\n",
      "step 7800, train accuracy 0.69\n",
      "step 8000, train accuracy 0.71\n",
      "step 8200, train accuracy 0.74\n",
      "step 8400, train accuracy 0.67\n",
      "step 8600, train accuracy 0.7\n",
      "step 8800, train accuracy 0.79\n",
      "step 9000, train accuracy 0.84\n",
      "step 9200, train accuracy 0.64\n",
      "step 9400, train accuracy 0.67\n",
      "step 9600, train accuracy 0.72\n",
      "step 9800, train accuracy 0.65\n",
      "step 10000, train accuracy 0.75\n",
      "step 10200, train accuracy 0.74\n",
      "step 10400, train accuracy 0.79\n",
      "step 10600, train accuracy 0.75\n",
      "step 10800, train accuracy 0.82\n",
      "step 11000, train accuracy 0.69\n",
      "step 11200, train accuracy 0.73\n",
      "step 11400, train accuracy 0.67\n",
      "step 11600, train accuracy 0.78\n",
      "step 11800, train accuracy 0.74\n",
      "step 12000, train accuracy 0.85\n",
      "step 12200, train accuracy 0.74\n",
      "step 12400, train accuracy 0.76\n",
      "step 12600, train accuracy 0.74\n",
      "step 12800, train accuracy 0.61\n",
      "step 13000, train accuracy 0.73\n",
      "step 13200, train accuracy 0.77\n",
      "step 13400, train accuracy 0.74\n",
      "step 13600, train accuracy 0.74\n",
      "step 13800, train accuracy 0.74\n",
      "step 14000, train accuracy 0.72\n",
      "step 14200, train accuracy 0.77\n",
      "step 14400, train accuracy 0.77\n",
      "step 14600, train accuracy 0.81\n",
      "step 14800, train accuracy 0.76\n",
      "step 15000, train accuracy 0.82\n",
      "step 15200, train accuracy 0.76\n",
      "step 15400, train accuracy 0.71\n",
      "step 15600, train accuracy 0.78\n",
      "step 15800, train accuracy 0.78\n",
      "step 16000, train accuracy 0.73\n",
      "step 16200, train accuracy 0.73\n",
      "step 16400, train accuracy 0.7\n",
      "step 16600, train accuracy 0.74\n",
      "step 16800, train accuracy 0.72\n",
      "step 17000, train accuracy 0.73\n",
      "step 17200, train accuracy 0.78\n",
      "step 17400, train accuracy 0.81\n",
      "step 17600, train accuracy 0.78\n",
      "step 17800, train accuracy 0.8\n",
      "step 18000, train accuracy 0.77\n",
      "step 18200, train accuracy 0.79\n",
      "step 18400, train accuracy 0.85\n",
      "step 18600, train accuracy 0.84\n",
      "step 18800, train accuracy 0.74\n",
      "step 19000, train accuracy 0.78\n",
      "step 19200, train accuracy 0.73\n",
      "step 19400, train accuracy 0.75\n",
      "step 19600, train accuracy 0.82\n",
      "step 19800, train accuracy 0.8\n",
      "step 20000, train accuracy 0.74\n",
      "step 20200, train accuracy 0.76\n",
      "step 20400, train accuracy 0.74\n",
      "step 20600, train accuracy 0.78\n",
      "step 20800, train accuracy 0.73\n",
      "step 21000, train accuracy 0.82\n",
      "step 21200, train accuracy 0.74\n",
      "step 21400, train accuracy 0.79\n",
      "step 21600, train accuracy 0.85\n",
      "step 21800, train accuracy 0.73\n",
      "step 22000, train accuracy 0.8\n",
      "step 22200, train accuracy 0.77\n",
      "step 22400, train accuracy 0.77\n",
      "step 22600, train accuracy 0.81\n",
      "step 22800, train accuracy 0.76\n",
      "step 23000, train accuracy 0.83\n",
      "step 23200, train accuracy 0.84\n",
      "step 23400, train accuracy 0.82\n",
      "step 23600, train accuracy 0.81\n",
      "step 23800, train accuracy 0.77\n",
      "step 24000, train accuracy 0.82\n",
      "step 24200, train accuracy 0.86\n",
      "step 24400, train accuracy 0.8\n",
      "step 24600, train accuracy 0.88\n",
      "step 24800, train accuracy 0.86\n",
      "step 25000, train accuracy 0.83\n",
      "step 25200, train accuracy 0.78\n",
      "step 25400, train accuracy 0.79\n",
      "step 25600, train accuracy 0.87\n",
      "step 25800, train accuracy 0.84\n",
      "step 26000, train accuracy 0.83\n",
      "step 26200, train accuracy 0.87\n",
      "step 26400, train accuracy 0.75\n",
      "step 26600, train accuracy 0.86\n",
      "step 26800, train accuracy 0.86\n",
      "step 27000, train accuracy 0.87\n",
      "step 27200, train accuracy 0.83\n",
      "step 27400, train accuracy 0.89\n",
      "step 27600, train accuracy 0.84\n",
      "step 27800, train accuracy 0.78\n",
      "step 28000, train accuracy 0.78\n",
      "step 28200, train accuracy 0.84\n",
      "step 28400, train accuracy 0.85\n",
      "step 28600, train accuracy 0.78\n",
      "step 28800, train accuracy 0.83\n",
      "step 29000, train accuracy 0.83\n",
      "step 29200, train accuracy 0.92\n",
      "step 29400, train accuracy 0.87\n",
      "step 29600, train accuracy 0.85\n",
      "step 29800, train accuracy 0.82\n",
      "step 30000, train accuracy 0.87\n",
      "step 30200, train accuracy 0.8\n",
      "step 30400, train accuracy 0.82\n",
      "step 30600, train accuracy 0.82\n",
      "step 30800, train accuracy 0.89\n",
      "step 31000, train accuracy 0.81\n",
      "step 31200, train accuracy 0.86\n",
      "step 31400, train accuracy 0.89\n",
      "step 31600, train accuracy 0.91\n",
      "step 31800, train accuracy 0.86\n",
      "step 32000, train accuracy 0.9\n",
      "step 32200, train accuracy 0.91\n",
      "step 32400, train accuracy 0.86\n",
      "step 32600, train accuracy 0.9\n",
      "step 32800, train accuracy 0.9\n",
      "step 33000, train accuracy 0.85\n",
      "step 33200, train accuracy 0.87\n",
      "step 33400, train accuracy 0.89\n",
      "step 33600, train accuracy 0.85\n",
      "step 33800, train accuracy 0.84\n",
      "step 34000, train accuracy 0.87\n",
      "step 34200, train accuracy 0.81\n",
      "step 34400, train accuracy 0.83\n",
      "step 34600, train accuracy 0.82\n",
      "step 34800, train accuracy 0.89\n",
      "step 35000, train accuracy 0.85\n",
      "step 35200, train accuracy 0.88\n",
      "step 35400, train accuracy 0.89\n",
      "step 35600, train accuracy 0.89\n",
      "step 35800, train accuracy 0.87\n",
      "step 36000, train accuracy 0.86\n",
      "step 36200, train accuracy 0.81\n",
      "step 36400, train accuracy 0.89\n",
      "step 36600, train accuracy 0.89\n",
      "step 36800, train accuracy 0.91\n",
      "step 37000, train accuracy 0.93\n",
      "step 37200, train accuracy 0.91\n",
      "step 37400, train accuracy 0.94\n",
      "step 37600, train accuracy 0.91\n",
      "step 37800, train accuracy 0.86\n",
      "step 38000, train accuracy 0.85\n",
      "step 38200, train accuracy 0.87\n",
      "step 38400, train accuracy 0.93\n",
      "step 38600, train accuracy 0.93\n",
      "step 38800, train accuracy 0.89\n",
      "step 39000, train accuracy 0.89\n",
      "step 39200, train accuracy 0.9\n",
      "step 39400, train accuracy 0.93\n",
      "step 39600, train accuracy 0.94\n",
      "step 39800, train accuracy 0.9\n",
      "step 40000, train accuracy 0.95\n",
      "step 40200, train accuracy 0.92\n",
      "step 40400, train accuracy 0.9\n",
      "step 40600, train accuracy 0.92\n",
      "step 40800, train accuracy 0.96\n",
      "step 41000, train accuracy 0.88\n",
      "step 41200, train accuracy 0.96\n",
      "step 41400, train accuracy 0.94\n",
      "step 41600, train accuracy 0.96\n",
      "step 41800, train accuracy 0.93\n",
      "step 42000, train accuracy 0.93\n",
      "step 42200, train accuracy 0.96\n",
      "step 42400, train accuracy 0.94\n",
      "step 42600, train accuracy 0.93\n",
      "step 42800, train accuracy 0.87\n",
      "step 43000, train accuracy 0.95\n",
      "step 43200, train accuracy 0.93\n",
      "step 43400, train accuracy 0.94\n",
      "step 43600, train accuracy 0.89\n",
      "step 43800, train accuracy 0.94\n",
      "step 44000, train accuracy 0.93\n",
      "step 44200, train accuracy 0.97\n",
      "step 44400, train accuracy 0.92\n",
      "step 44600, train accuracy 0.95\n",
      "step 44800, train accuracy 0.96\n",
      "step 45000, train accuracy 0.93\n",
      "step 45200, train accuracy 0.92\n",
      "step 45400, train accuracy 0.95\n",
      "step 45600, train accuracy 0.94\n",
      "step 45800, train accuracy 0.92\n",
      "step 46000, train accuracy 0.96\n",
      "step 46200, train accuracy 0.94\n",
      "step 46400, train accuracy 0.93\n",
      "step 46600, train accuracy 0.98\n",
      "step 46800, train accuracy 0.96\n",
      "step 47000, train accuracy 0.95\n",
      "step 47200, train accuracy 0.97\n",
      "step 47400, train accuracy 0.94\n",
      "step 47600, train accuracy 0.97\n",
      "step 47800, train accuracy 0.97\n",
      "step 48000, train accuracy 0.93\n",
      "step 48200, train accuracy 1\n",
      "step 48400, train accuracy 0.96\n",
      "step 48600, train accuracy 0.96\n",
      "step 48800, train accuracy 0.99\n",
      "step 49000, train accuracy 0.93\n",
      "step 49200, train accuracy 0.92\n",
      "step 49400, train accuracy 0.92\n",
      "step 49600, train accuracy 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49800, train accuracy 0.93\n",
      "step 50000, train accuracy 0.95\n",
      "step 50200, train accuracy 0.97\n",
      "step 50400, train accuracy 0.99\n",
      "step 50600, train accuracy 0.99\n",
      "step 50800, train accuracy 0.98\n",
      "step 51000, train accuracy 0.97\n",
      "step 51200, train accuracy 0.98\n",
      "step 51400, train accuracy 0.97\n",
      "step 51600, train accuracy 0.98\n",
      "step 51800, train accuracy 0.96\n",
      "step 52000, train accuracy 0.94\n",
      "step 52200, train accuracy 0.99\n",
      "step 52400, train accuracy 0.96\n",
      "step 52600, train accuracy 0.98\n",
      "step 52800, train accuracy 0.95\n",
      "step 53000, train accuracy 0.94\n",
      "step 53200, train accuracy 0.97\n",
      "step 53400, train accuracy 0.95\n",
      "step 53600, train accuracy 0.99\n",
      "step 53800, train accuracy 0.99\n",
      "step 54000, train accuracy 0.99\n",
      "step 54200, train accuracy 0.95\n",
      "step 54400, train accuracy 0.97\n",
      "step 54600, train accuracy 0.93\n",
      "step 54800, train accuracy 0.97\n",
      "step 55000, train accuracy 0.97\n",
      "step 55200, train accuracy 0.96\n",
      "step 55400, train accuracy 0.98\n",
      "step 55600, train accuracy 1\n",
      "step 55800, train accuracy 0.98\n",
      "step 56000, train accuracy 0.99\n",
      "step 56200, train accuracy 0.98\n",
      "step 56400, train accuracy 0.98\n",
      "step 56600, train accuracy 0.95\n",
      "step 56800, train accuracy 0.98\n",
      "step 57000, train accuracy 0.99\n",
      "step 57200, train accuracy 0.99\n",
      "step 57400, train accuracy 0.97\n",
      "step 57600, train accuracy 0.99\n",
      "step 57800, train accuracy 0.96\n",
      "step 58000, train accuracy 0.99\n",
      "step 58200, train accuracy 0.97\n",
      "step 58400, train accuracy 1\n",
      "step 58600, train accuracy 0.98\n",
      "step 58800, train accuracy 0.99\n",
      "step 59000, train accuracy 0.95\n",
      "step 59200, train accuracy 1\n",
      "step 59400, train accuracy 1\n",
      "step 59600, train accuracy 1\n",
      "step 59800, train accuracy 1\n",
      "step 60000, train accuracy 0.98\n",
      "step 60200, train accuracy 0.99\n",
      "step 60400, train accuracy 0.99\n",
      "step 60600, train accuracy 0.99\n",
      "step 60800, train accuracy 0.99\n",
      "step 61000, train accuracy 0.98\n",
      "step 61200, train accuracy 0.99\n",
      "step 61400, train accuracy 1\n",
      "step 61600, train accuracy 0.98\n",
      "step 61800, train accuracy 1\n",
      "step 62000, train accuracy 1\n",
      "step 62200, train accuracy 0.99\n",
      "step 62400, train accuracy 0.98\n",
      "step 62600, train accuracy 0.99\n",
      "step 62800, train accuracy 0.99\n",
      "step 63000, train accuracy 0.99\n",
      "step 63200, train accuracy 1\n",
      "step 63400, train accuracy 1\n",
      "step 63600, train accuracy 0.98\n",
      "step 63800, train accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "# start tensorflow interactiveSession                baseline           F1 = 0.7606992164\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#####################################################     Net Define     ##################################################### \n",
    "\n",
    "# weight initialization\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# convolution\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# pooling\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Create the model\n",
    "# placeholder\n",
    "x = tf.placeholder(\"float\", [None, 2500])\n",
    "y_ = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "\n",
    "# first convolutinal layer\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 50, 50, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# second convolutional layer\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# densely connected layer\n",
    "w_fc1 = weight_variable([13*13*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 13*13*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# readout layer\n",
    "w_fc2 = weight_variable([1024, 3])\n",
    "b_fc2 = bias_variable([3])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)\n",
    "\n",
    "# train and evaluate the model\n",
    "#交叉熵作为损失函数\n",
    "delta = 1e-7\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv+delta))\n",
    "train_step = tf.train.GradientDescentOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "\n",
    "#####################################################       Train     ##################################################### \n",
    "\n",
    "image_path = 'E:/Age Detection of Indian Actors/train_DETg9GD/Train_Gray/'\n",
    "data_path = 'E:/Age Detection of Indian Actors/train_DETg9GD/Train.csv'\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data = pd.get_dummies(data,columns = ['Class'])\n",
    "\n",
    "\n",
    "def get_batch(data,batch_rate,seed):\n",
    "    \"\"\"\n",
    "    本函数实现从训练集中随机抽取部分图像，格式适合输入tensorflow，同时得到样本label的独热编码\n",
    "    input:\n",
    "        batch_rate:    batch占训练集数据的比例\n",
    "        data:          DataFrame       train.csv\n",
    "        seed:          随机种子\n",
    "    output:\n",
    "        train_x:        训练图像tensor\n",
    "        train_y:        训练图像one_hot编码的label\n",
    "    \"\"\"\n",
    "    sample = data.sample(frac = batch_rate, random_state = seed)\n",
    "    sample.index = list(range(0,sample.shape[0]))\n",
    "    one_hot_sample = sample.drop(['ID'], axis = 1)\n",
    "    train_y = one_hot_sample.values\n",
    "    train_x = []\n",
    "    for i in range(0,sample.shape[0]):\n",
    "        image = image_path + sample.ID[i]\n",
    "        im = np.array(Image.open(image))/255.0\n",
    "        im = im.flatten()\n",
    "        train_x.append(im)\n",
    "    train_x = np.array(train_x)\n",
    "    \n",
    "    return train_x,train_y\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "batch_rate = 0.005\n",
    "for i in range(64000):\n",
    "    batch_x,batch_y = get_batch(data,batch_rate,i)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_x, y_:batch_y, keep_prob:1.0})\n",
    "        print (\"step %d, train accuracy %g\" %(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch_x, y_:batch_y, keep_prob:0.5})\n",
    "\n",
    "#print (\"test accuracy %g\" % accuracy.eval(feed_dict={x:mnist.test.images, y_:mnist.test.labels, keep_prob:1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'E:/Age Detection of Indian Actors/test_Bh8pGW3/Test_Gray/'\n",
    "\n",
    "test = pd.read_csv('E:/Age Detection of Indian Actors/test_Bh8pGW3/test.csv')\n",
    "\n",
    "test_x = []\n",
    "for i in range(0,test.shape[0]):\n",
    "    image = image_path + test.ID[i]\n",
    "    im = np.array(Image.open(image))/255.0\n",
    "    im = im.flatten()\n",
    "    test_x.append(im)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.zeros((test.shape[0],3))\n",
    "\n",
    "pred = tf.argmax(y_conv, 1)\n",
    "\n",
    "test_x_0 = test_x[0:1500]\n",
    "test_y_0 = test_y[0:1500]\n",
    "P_0 = pred.eval(feed_dict={x:test_x_0, y_:test_y_0, keep_prob:1.0})\n",
    "\n",
    "test_x_1 = test_x[1500:3000]\n",
    "test_y_1 = test_y[1500:3000]\n",
    "P_1 = pred.eval(feed_dict={x:test_x_1, y_:test_y_1, keep_prob:1.0})\n",
    "\n",
    "test_x_2 = test_x[3000:4500]\n",
    "test_y_2 = test_y[3000:4500]\n",
    "P_2 = pred.eval(feed_dict={x:test_x_2, y_:test_y_2, keep_prob:1.0})\n",
    "\n",
    "test_x_3 = test_x[4500:]\n",
    "test_y_3 = test_y[4500:]\n",
    "P_3 = pred.eval(feed_dict={x:test_x_3, y_:test_y_3, keep_prob:3.0})\n",
    "\n",
    "P = np.hstack([P_0,P_1,P_2,P_3])\n",
    "\n",
    "test['pred'] = P\n",
    "\n",
    "Dict = {0:'MIDDLE',1:'OLD', 2:'YOUNG'}\n",
    "Class = []\n",
    "for i in range(0,test.shape[0]):\n",
    "    Class.append(Dict.get(test['pred'][i]))\n",
    "    \n",
    "pred = pd.DataFrame({'Class':Class,'ID':test.ID})\n",
    "pred.head()\n",
    "\n",
    "pred.to_csv('50_gray_pix_pred_64k_batch.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
